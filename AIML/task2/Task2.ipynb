{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a02e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342423c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6000, 5)\n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "0.0    5880\n",
      "1.0     120\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.509005</td>\n",
       "      <td>30.471488</td>\n",
       "      <td>112.233421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.515029</td>\n",
       "      <td>20.536776</td>\n",
       "      <td>82.508700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.117653</td>\n",
       "      <td>37.428296</td>\n",
       "      <td>77.176741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.666161</td>\n",
       "      <td>25.325802</td>\n",
       "      <td>75.218541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.351145</td>\n",
       "      <td>34.765768</td>\n",
       "      <td>82.418838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2   feature_3  feature_4  target\n",
       "0  23.509005  30.471488  112.233421        0.0     0.0\n",
       "1  63.515029  20.536776   82.508700        0.0     0.0\n",
       "2  59.117653  37.428296   77.176741        0.0     0.0\n",
       "3  32.666161  25.325802   75.218541        0.0     0.0\n",
       "4  29.351145  34.765768   82.418838        0.0     0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 6000\n",
    "\n",
    "y = np.zeros(n_samples)\n",
    "y[:120] = 1\n",
    "np.random.shuffle(y)\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    \"feature_1\": np.random.normal(50, 10, n_samples),\n",
    "    \"feature_2\": np.random.normal(30, 5, n_samples),\n",
    "    \"feature_3\": np.random.normal(100, 20, n_samples),\n",
    "    \"feature_4\": y\n",
    "})\n",
    "\n",
    "df = X.copy()\n",
    "df[\"target\"] = y\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df[\"target\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac181f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4800 samples\n",
      "Test set: 1200 samples\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31b3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Original Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02e145",
   "metadata": {},
   "source": [
    "## Problem Identified\n",
    "\n",
    "The accuracy looks extremely high, which immediately raises suspicion. After reviewing the data generation code, I found the issue: feature_4 is identical to the target variable. This is called target leakage.\n",
    "\n",
    "When creating the features, the code does this:\n",
    "\n",
    "```python\n",
    "\"feature_4\": y\n",
    "```\n",
    "\n",
    "This means the model has direct access to the answer during training. It's like giving students the answer key before a test. The model isn't learning patterns, it's just copying feature_4 to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cea2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for target leakage:\n",
      "\n",
      "Are feature_4 and target identical? True\n",
      "\n",
      "Correlation between feature_4 and target: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for target leakage:\")\n",
    "print(f\"\\nAre feature_4 and target identical? {(df['feature_4'] == df['target']).all()}\")\n",
    "print(f\"\\nCorrelation between feature_4 and target: {df['feature_4'].corr(df['target']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a640a77",
   "metadata": {},
   "source": [
    "## Corrected Implementation\n",
    "\n",
    "The fix is simple: remove feature_4 since it contains leaked information. The other three features are just random noise with no actual relationship to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "117b2470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned features:\n",
      "['feature_1', 'feature_2', 'feature_3']\n",
      "\n",
      "Shape: (6000, 3)\n"
     ]
    }
   ],
   "source": [
    "X_clean = df.drop([\"target\", \"feature_4\"], axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "print(\"Cleaned features:\")\n",
    "print(X_clean.columns.tolist())\n",
    "print(f\"\\nShape: {X_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad180740",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(\n",
    "    X_clean, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_clean = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_clean.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "y_pred_clean = model_clean.predict(X_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5771d",
   "metadata": {},
   "source": [
    "## Proper Evaluation\n",
    "\n",
    "Now let's evaluate the model correctly without the leaked feature. The dataset is imbalanced (only 2% positive class), so accuracy alone is misleading. I'll look at precision, recall, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf08b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Model Performance:\n",
      "Accuracy:  0.980\n",
      "Precision: 0.000\n",
      "Recall:    0.000\n",
      "F1-score:  0.000\n"
     ]
    }
   ],
   "source": [
    "accuracy_clean = accuracy_score(y_test_clean, y_pred_clean)\n",
    "precision = precision_score(y_test_clean, y_pred_clean, zero_division=0)\n",
    "recall = recall_score(y_test_clean, y_pred_clean)\n",
    "f1 = f1_score(y_test_clean, y_pred_clean)\n",
    "\n",
    "print(\"Corrected Model Performance:\")\n",
    "print(f\"Accuracy:  {accuracy_clean:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da7ffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[1176    0]\n",
      " [  24    0]]\n",
      "\n",
      "True Negatives:  1176\n",
      "False Positives: 0\n",
      "False Negatives: 24\n",
      "True Positives:  0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_clean, y_pred_clean)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nTrue Negatives:  {cm[0,0]}\")\n",
    "print(f\"False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]}\")\n",
    "print(f\"True Positives:  {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63cd6d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      1.00      0.99      1176\n",
      "    Positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.49      0.50      0.49      1200\n",
      "weighted avg       0.96      0.98      0.97      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aakif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aakif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\aakif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test_clean, y_pred_clean, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458f505",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "The original model had near-perfect accuracy because it was cheating. Feature_4 was identical to the target, so the model just learned to copy that value.\n",
    "\n",
    "After removing the leaked feature, the model predicts only the negative class (majority class) because the remaining features are just random noise with no real relationship to the target. The high accuracy we see now (around 98%) is misleading for a different reason: it's simply predicting the majority class most of the time.\n",
    "\n",
    "With only 2% positive samples, a model that always predicts negative would get 98% accuracy. Looking at the confusion matrix and recall shows the model isn't actually learning anything useful.\n",
    "\n",
    "This demonstrates why accuracy alone is a poor metric for imbalanced datasets and why we must carefully check for data leakage during model development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
